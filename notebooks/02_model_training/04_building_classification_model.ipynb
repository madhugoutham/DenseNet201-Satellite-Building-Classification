{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install tensorflow keras numpy pandas matplotlib scikit-learn keras-tuner building_footprint_segmentation"],"metadata":{"id":"GKdShPXOragg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729522481726,"user_tz":300,"elapsed":5762,"user":{"displayName":"Madhu","userId":"04770105201828297773"}},"outputId":"757bc3cf-0561-4171-813a-1140f0442614"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n","Collecting building_footprint_segmentation\n","  Downloading building_footprint_segmentation-0.2.4-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Collecting kt-legacy (from keras-tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n","Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading building_footprint_segmentation-0.2.4-py3-none-any.whl (35 kB)\n","Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Installing collected packages: kt-legacy, building_footprint_segmentation, keras-tuner\n","Successfully installed building_footprint_segmentation-0.2.4 keras-tuner-1.4.7 kt-legacy-1.0.5\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZLs9atikwM2","executionInfo":{"status":"ok","timestamp":1729522523237,"user_tz":300,"elapsed":19848,"user":{"displayName":"Madhu","userId":"04770105201828297773"}},"outputId":"fe06759f-98af-4125-9c15-d5c49521c52b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UQ6DRuf3qoCp","colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"status":"error","timestamp":1729522534442,"user_tz":300,"elapsed":8899,"user":{"displayName":"Madhu","userId":"04770105201828297773"}},"outputId":"eb0f19e6-9c4f-4e68-d11f-d094d7b8b541"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPUs Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","\n","Training with all classes included:\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Madhu RA Work Folder/Img/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9de022897363>\u001b[0m in \u001b[0;36m<cell line: 184>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;31m# All classes included\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining with all classes included:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'All classes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# Excluding each class one by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9de022897363>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(excluded_classes, base_dir, img_size, batch_size, epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Get class names from training directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Collect data paths excluding specified classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9de022897363>\u001b[0m in \u001b[0;36mget_class_names\u001b[0;34m(data_directory)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Function to get class names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Madhu RA Work Folder/Img/train'"]}],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import DenseNet201\n","from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import confusion_matrix, classification_report\n","from PIL import Image\n","\n","# Enable mixed precision training\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy('mixed_float16')\n","\n","# Verify GPU availability\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    print(\"GPUs Available:\", gpus)\n","else:\n","    print(\"No GPU found. Please ensure that TensorFlow is configured properly.\")\n","\n","# Set the image size and batch size\n","img_size = (224, 224)\n","batch_size = 32\n","\n","# Set the base directory for the data\n","base_dir = '/content/drive/MyDrive/Madhu RA Work Folder/Img' # Adjust this path as needed\n","\n","# Function to get class names\n","def get_class_names(data_directory):\n","    class_names = sorted([item for item in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, item))])\n","    print(\"Classes:\", class_names)\n","    return class_names\n","\n","# Function to collect data paths excluding specified classes\n","def collect_data_paths(data_directory, excluded_classes, class_names):\n","    image_paths = []\n","    labels = []\n","    included_class_names = [cls for cls in class_names if cls not in excluded_classes]\n","    class_indices = {class_name: idx for idx, class_name in enumerate(included_class_names)}\n","    for class_name in included_class_names:\n","        folder_path = os.path.join(data_directory, class_name)\n","        if os.path.isdir(folder_path):\n","            for img_file in os.listdir(folder_path):\n","                img_path = os.path.join(folder_path, img_file)\n","                # Filter out non-image files\n","                if img_file.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n","                    image_paths.append(img_path)\n","                    labels.append(class_indices[class_name])\n","    return image_paths, labels, included_class_names\n","\n","# Function to load and preprocess image with PIL\n","def load_image_with_pil(filename):\n","    filename = filename.decode('utf-8')  # Decode the bytes object\n","    image = Image.open(filename).convert('RGB')\n","    image = image.resize(img_size)\n","    image = np.array(image) / 255.0  # Normalize to [0,1]\n","    return image.astype(np.float32)\n","\n","# Function to parse and preprocess images using PIL\n","def parse_function(filename, label):\n","    # Read image using PIL via tf.numpy_function\n","    image = tf.numpy_function(load_image_with_pil, [filename], tf.float32)\n","    image.set_shape([img_size[0], img_size[1], 3])  # Set static shape\n","    return image, label\n","\n","# Data augmentation using Keras preprocessing layers\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip('horizontal'),\n","    tf.keras.layers.RandomRotation(0.1),\n","    tf.keras.layers.RandomZoom(0.1),\n","])\n","\n","# Function to create datasets\n","def create_dataset(image_paths, labels, training=True):\n","    labels = np.array(labels)\n","    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n","    dataset = dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n","    if training:\n","        dataset = dataset.shuffle(buffer_size=1024)\n","        dataset = dataset.batch(batch_size)\n","        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n","    else:\n","        dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n","    return dataset\n","\n","# Function to build the model using best hyperparameters\n","def build_model(num_classes):\n","    with tf.device('/GPU:0'):\n","        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n","        # Fine-tune starting at the specified layer\n","        for layer in base_model.layers[:500]:\n","            layer.trainable = False\n","        for layer in base_model.layers[500:]:\n","            layer.trainable = True\n","\n","        # Input layer\n","        inputs = Input(shape=(img_size[0], img_size[1], 3))\n","        x = inputs\n","        x = base_model(x, training=True)\n","        x = GlobalAveragePooling2D()(x)\n","        x = Dense(768, activation='relu')(x)\n","        x = Dropout(0.4)(x)\n","        outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)  # Use float32 for final layer\n","\n","        model = Model(inputs, outputs)\n","\n","        # Compile the model\n","        optimizer = Adam(learning_rate=5.838015556029658e-05)\n","        optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n","        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Function to train and evaluate the model with excluded classes\n","def train_and_evaluate(excluded_classes, base_dir, img_size=(224, 224), batch_size=32, epochs=20):\n","    # Get class names from training directory\n","    data_dir = os.path.join(base_dir, 'train')\n","    class_names = get_class_names(data_dir)\n","\n","    # Collect data paths excluding specified classes\n","    train_paths, train_labels, included_class_names = collect_data_paths(os.path.join(base_dir, 'train'), excluded_classes, class_names)\n","    val_paths, val_labels, _ = collect_data_paths(os.path.join(base_dir, 'val'), excluded_classes, class_names)\n","    test_paths, test_labels, _ = collect_data_paths(os.path.join(base_dir, 'test'), excluded_classes, class_names)\n","\n","    num_classes = len(included_class_names)\n","    print(f\"Training with classes: {included_class_names}\")\n","\n","    # Create datasets\n","    train_dataset = create_dataset(train_paths, train_labels, training=True)\n","    val_dataset = create_dataset(val_paths, val_labels, training=False)\n","    test_dataset = create_dataset(test_paths, test_labels, training=False)\n","\n","    # Build the model\n","    model = build_model(num_classes)\n","\n","    # Implement early stopping\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","    # Train the model\n","    history = model.fit(\n","        train_dataset,\n","        epochs=epochs,\n","        validation_data=val_dataset,\n","        callbacks=[early_stopping]\n","    )\n","\n","    # Save the model\n","    excluded_classes_str = '_'.join(excluded_classes) if excluded_classes else 'all_classes'\n","    model.save(f'Densenet201_excluded_{excluded_classes_str}.h5')\n","\n","    # Evaluate the model on the test set\n","    test_loss, test_accuracy = model.evaluate(test_dataset)\n","    print(f\"Test Accuracy excluding {excluded_classes}: {test_accuracy:.4%}\")\n","\n","    # Generate confusion matrix and classification report\n","    y_true = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)\n","    y_pred_probs = model.predict(test_dataset)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","\n","    # Adjust class names for the included classes\n","    included_class_indices = {idx: class_name for idx, class_name in enumerate(included_class_names)}\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    print(\"Confusion Matrix:\\n\", cm)\n","\n","    # Define labels for classification report\n","    labels = range(num_classes)\n","\n","    # Classification Report\n","    cr = classification_report(y_true, y_pred, labels=labels, target_names=included_class_names, zero_division=0)\n","    print(\"Classification Report:\\n\", cr)\n","\n","    return test_accuracy\n","\n","# Testing different class exclusions\n","results = {}\n","\n","# All classes included\n","print(\"\\nTraining with all classes included:\")\n","results['All classes'] = train_and_evaluate([], base_dir)\n","\n","# Excluding each class one by one\n","classes_to_exclude = ['Commercial', 'High', 'Hospital', 'Industrial', 'Multi', 'Schools', 'Single']\n","\n","for cls in classes_to_exclude:\n","    print(f\"\\nExcluding class: {cls}\")\n","    results[f'No {cls}'] = train_and_evaluate([cls], base_dir)\n","\n","# Print results\n","print(\"\\nSummary of Results:\")\n","for key, value in results.items():\n","    print(f'{key}: {value:.4%}')\n"]}]}