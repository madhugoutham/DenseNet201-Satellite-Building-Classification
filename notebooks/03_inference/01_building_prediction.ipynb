{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install tensorflow keras numpy pandas matplotlib scikit-learn keras-tuner building_footprint_segmentation"],"metadata":{"id":"3PCiCn1THRa-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729042739348,"user_tz":300,"elapsed":4338,"user":{"displayName":"Madhu Goutham Reddy Ambati","userId":"13555911222953113464"}},"outputId":"e0a0128a-cb8b-4952-bb85-be9d4f296df0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n","Collecting building_footprint_segmentation\n","  Downloading building_footprint_segmentation-0.2.4-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Collecting kt-legacy (from keras-tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n","Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading building_footprint_segmentation-0.2.4-py3-none-any.whl (35 kB)\n","Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Installing collected packages: kt-legacy, building_footprint_segmentation, keras-tuner\n","Successfully installed building_footprint_segmentation-0.2.4 keras-tuner-1.4.7 kt-legacy-1.0.5\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"0aELuK_NIgZu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729042754135,"user_tz":300,"elapsed":14078,"user":{"displayName":"Madhu Goutham Reddy Ambati","userId":"13555911222953113464"}},"outputId":"cb7afc27-fb5f-4d6c-ba56-aa41b3948695"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#Section 1: Imports and Constants"],"metadata":{"id":"s78OD-22HuBx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MwsLEMGHEUE"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import random\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.applications.densenet import preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","from building_footprint_segmentation.seg.binary.models import ReFineNet\n","from building_footprint_segmentation.helpers.normalizer import min_max_image_net\n","from building_footprint_segmentation.utils.py_network import (\n","    to_input_image_tensor, add_extra_dimension, adjust_model\n",")\n","\n","# Constants\n","MAX_SIZE = 512\n","MODEL_URL = \"https://github.com/fuzailpalnak/building-footprint-segmentation/releases/download/alpha/refine.zip\"\n","THRESHOLD = 0.4\n","MIN_BUILDING_SIZE = 500\n","MAX_BUILDING_SIZE = 100000"]},{"cell_type":"markdown","source":["#Section 2: Building Detection Model Functions"],"metadata":{"id":"t9uhG2bqHz0S"}},{"cell_type":"code","source":["def get_trained_model():\n","    model = ReFineNet()\n","    set_model_weights(model)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","    return model, device\n","\n","def set_model_weights(model):\n","    cache_dir = \"./model_weights\"\n","    os.makedirs(cache_dir, exist_ok=True)\n","    weights_path = os.path.join(cache_dir, \"refine.pth\")\n","    if not os.path.exists(weights_path):\n","        state_dict = torch.hub.load_state_dict_from_url(MODEL_URL, progress=True, map_location=\"cpu\")\n","        torch.save(state_dict, weights_path)\n","    else:\n","        state_dict = torch.load(weights_path, map_location=\"cpu\")\n","    if \"model\" in state_dict:\n","        state_dict = state_dict[\"model\"]\n","    model.load_state_dict(adjust_model(state_dict))"],"metadata":{"id":"CC1AE6zpHSxN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 3: Image Processing Functions"],"metadata":{"id":"IxuxNuthH52A"}},{"cell_type":"code","source":["def resize_image(image):\n","    original_height, original_width = image.shape[:2]\n","    if (original_height != MAX_SIZE) or (original_width != MAX_SIZE):\n","        resized_image = cv2.resize(image, (MAX_SIZE, MAX_SIZE), interpolation=cv2.INTER_AREA)\n","        return resized_image\n","    return image\n","\n","# Implement Test-Time Augmentation (TTA)\n","def predict_with_tta(model, device, image_tensor):\n","    # Original prediction\n","    prediction = model(image_tensor).sigmoid()\n","    predictions = [prediction]\n","\n","    # Augmentations: horizontal flip, vertical flip\n","    flips = [torch.flip(image_tensor, dims=[3]), torch.flip(image_tensor, dims=[2])]\n","\n","    for flip in flips:\n","        pred_flip = model(flip).sigmoid()\n","        # Flip back\n","        if flip is flips[0]:\n","            pred_flip = torch.flip(pred_flip, dims=[3])\n","        else:\n","            pred_flip = torch.flip(pred_flip, dims=[2])\n","        predictions.append(pred_flip)\n","\n","    # Average the predictions\n","    prediction_avg = torch.mean(torch.stack(predictions), dim=0)\n","    return prediction_avg\n","\n","# Extract building mask and generate binary output\n","def extract(model, device, original_image):\n","    # Resize and normalize image\n","    resized_image = resize_image(original_image)\n","    normalized_image = min_max_image_net(img=resized_image)\n","    tensor_image = add_extra_dimension(to_input_image_tensor(normalized_image)).to(device)\n","\n","    with torch.no_grad():\n","        # Predict building segmentation with TTA\n","        prediction = predict_with_tta(model, device, tensor_image)\n","\n","    # Convert prediction to binary mask with adjusted threshold\n","    prediction_numpy = prediction.cpu().numpy()[0, 0]\n","    pred_binary = (prediction_numpy > THRESHOLD).astype(np.uint8)\n","\n","    # Removed visualization of raw segmentation output and binary mask\n","\n","    # Post-process the binary mask to remove noise and separate attached buildings\n","    cleaned_mask = postprocess_mask(pred_binary)\n","\n","    # Removed visualization of cleaned mask after post-processing\n","\n","    return cleaned_mask, resized_image"],"metadata":{"id":"nZ6zVI2NHS3-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 4: Mask Post-processing Functions"],"metadata":{"id":"dPYC4Oj5IAKK"}},{"cell_type":"code","source":["# Post-process the mask to remove small regions, noise, and separate attached buildings\n","def postprocess_mask(mask):\n","    # Apply morphological opening to remove small connections\n","    kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open, iterations=2)\n","\n","    # Separate attached buildings using watershed algorithm\n","    separated_mask = separate_attached_buildings(mask)\n","\n","    # Remove small and large connected components\n","    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(separated_mask, connectivity=8)\n","    sizes = stats[1:, cv2.CC_STAT_AREA]\n","    final_mask = np.zeros((labels.shape), np.uint8)\n","\n","    for i in range(0, num_labels - 1):\n","        area = sizes[i]\n","        if MIN_BUILDING_SIZE <= area <= MAX_BUILDING_SIZE:\n","            final_mask[labels == i + 1] = 1\n","\n","    return final_mask\n","\n","# Function to separate attached buildings using watershed algorithm\n","def separate_attached_buildings(mask):\n","    # Compute the distance transform\n","    distance = cv2.distanceTransform(mask, cv2.DIST_L2, 5)\n","    # Normalize the distance image for display\n","    cv2.normalize(distance, distance, 0, 1.0, cv2.NORM_MINMAX)\n","    # Adjusted threshold to capture more peaks\n","    ret, sure_fg = cv2.threshold(distance, 0.1, 1.0, cv2.THRESH_BINARY)\n","    # Increase dilation iterations to better separate buildings\n","    kernel = np.ones((3, 3), np.uint8)\n","    sure_fg = cv2.dilate(sure_fg, kernel, iterations=2)\n","    # Finding unknown region\n","    sure_bg = cv2.dilate(mask, kernel, iterations=3)\n","    unknown = cv2.subtract(sure_bg, np.uint8(sure_fg))\n","    # Marker labeling\n","    ret, markers = cv2.connectedComponents(np.uint8(sure_fg))\n","    # Add one to all labels so that sure background is not 0, but 1\n","    markers = markers + 1\n","    # Mark the unknown regions with zero\n","    markers[unknown == 1] = 0\n","    # Apply watershed\n","    markers = cv2.watershed(cv2.cvtColor(mask * 255, cv2.COLOR_GRAY2BGR), markers)\n","    # Generate new mask with separated buildings\n","    separated_mask = np.zeros_like(mask)\n","    separated_mask[markers > 1] = 1\n","\n","    # Removed visualization of markers for watershed\n","\n","    return separated_mask"],"metadata":{"id":"V_z7kFt-HS89"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 5: Building Classification Functions"],"metadata":{"id":"KdnPfzlsIGjL"}},{"cell_type":"code","source":["# Function to classify multiple building regions in a batch with extended bounding boxes\n","def classify_building_regions(image, contours, model, class_labels, padding=10):\n","    image_height, image_width = image.shape[:2]\n","    building_regions = []\n","    bboxes = []\n","\n","    for contour in contours:\n","        # Extract the bounding box for the contour\n","        x, y, w, h = cv2.boundingRect(contour)\n","\n","        # Extend the bounding box with padding\n","        x_new = max(0, x - padding)\n","        y_new = max(0, y - padding)\n","        x_max = min(image_width, x + w + padding)\n","        y_max = min(image_height, y + h + padding)\n","        w_new = x_max - x_new\n","        h_new = y_max - y_new\n","\n","        # Extract the extended building region\n","        building_region = image[y_new:y_new + h_new, x_new:x_new + w_new]\n","\n","        # Resize to match the input size of the classifier\n","        resized_region = cv2.resize(building_region, (224, 224))\n","        building_regions.append(resized_region)\n","        bboxes.append((x_new, y_new, w_new, h_new))\n","\n","    if not building_regions:\n","        return []\n","\n","    # Convert to array suitable for the classifier\n","    region_array = np.array([img_to_array(region) for region in building_regions])\n","    region_array = preprocess_input(region_array)\n","\n","    # Predict using the classification model\n","    predictions = model.predict(region_array)\n","    top_class_indices = np.argmax(predictions, axis=1)\n","    probabilities = np.max(predictions, axis=1)\n","    top_classes = [class_labels[idx] for idx in top_class_indices]\n","\n","    results = list(zip(top_classes, probabilities, bboxes))\n","    return results"],"metadata":{"id":"Z5ekccnGHTB3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 6: Single Image Processing Function"],"metadata":{"id":"PHqbiLn5ILiI"}},{"cell_type":"code","source":["# Process each image: segment it, classify detected buildings, and store results\n","def process_single_image(image_path, actual_class, model, device, classification_model, class_labels, visualize=False):\n","    try:\n","        # Load the original image\n","        original_image = cv2.imread(image_path)\n","        if original_image is None:\n","            raise ValueError(f\"Error reading image {image_path}\")\n","\n","        # Convert to RGB\n","        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n","\n","        # Run the building segmentation model\n","        pred_binary, resized_image = extract(model, device, original_image)\n","\n","        # Find building contours\n","        contours, _ = cv2.findContours(pred_binary.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        building_contours = []\n","        for contour in contours:\n","            area = cv2.contourArea(contour)\n","            if MIN_BUILDING_SIZE <= area <= MAX_BUILDING_SIZE:\n","                building_contours.append(contour)\n","\n","        # Show the number of buildings detected\n","        num_buildings = len(building_contours)\n","        print(f\"{os.path.basename(image_path)}: Detected {num_buildings} building(s)\")\n","\n","        correct_predictions = 0\n","        total_predictions = 0\n","        vis_image = resized_image.copy()\n","        per_building_results = []  # List to store per-building results\n","\n","        if num_buildings > 0:\n","            # Classify building regions in batch with extended bounding boxes\n","            classification_results = classify_building_regions(\n","                resized_image, building_contours, classification_model, class_labels, padding=20)\n","\n","            # Draw bounding boxes and labels\n","            for i, (top_class, probability, bbox) in enumerate(classification_results):\n","                x, y, w, h = bbox\n","\n","                # Draw bounding box (thin red box)\n","                cv2.rectangle(vis_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","\n","                # Prepare label text\n","                label = f\"Predicted: {top_class} ({probability:.2f})\\nActual: {actual_class}\"\n","                y_offset = y - 10 if y - 10 > 10 else y + h + 20\n","\n","                # Split label into lines\n","                label_lines = label.split('\\n')\n","                font_scale = 0.5\n","                font = cv2.FONT_HERSHEY_SIMPLEX\n","                font_thickness = 1\n","\n","                # Calculate text size for background rectangle\n","                text_sizes = [cv2.getTextSize(line, font, font_scale, font_thickness)[0] for line in label_lines]\n","                text_width = max([w for (w, h) in text_sizes])\n","                text_height = sum([h + 5 for (w, h) in text_sizes])\n","\n","                # Set background rectangle coordinates\n","                rect_x1 = x\n","                rect_y1 = y_offset - text_height if y_offset - text_height > 0 else y_offset\n","                rect_x2 = x + text_width + 10\n","                rect_y2 = y_offset + 5\n","\n","                # Draw filled rectangle for text background\n","                cv2.rectangle(vis_image, (rect_x1, rect_y1), (rect_x2, rect_y2), (255, 255, 255), -1)\n","\n","                # Put text on the image\n","                text_y = rect_y1 + text_sizes[0][1] + 5\n","                for idx, line in enumerate(label_lines):\n","                    cv2.putText(vis_image, line, (x + 5, text_y), font, font_scale, (0, 0, 0), font_thickness)\n","                    text_y += text_sizes[idx][1] + 5\n","\n","                # Print the classification result\n","                print(f\"Building {i + 1} in {os.path.basename(image_path)}: Predicted: {top_class} ({probability:.4f}), Actual: {actual_class}\")\n","\n","                # Update accuracy counts\n","                total_predictions += 1\n","                if top_class == actual_class:\n","                    correct_predictions += 1\n","\n","                # Store per-building result\n","                result = {\n","                    'actual_class': actual_class,\n","                    'predicted_class': top_class,\n","                    'correct': top_class == actual_class\n","                }\n","                per_building_results.append(result)\n","\n","            if visualize:\n","                plt.figure(figsize=(10, 10))\n","                plt.imshow(vis_image)\n","                plt.title(f\"Detected Buildings and Classifications in {os.path.basename(image_path)}\")\n","                plt.axis('off')\n","                plt.show()\n","        else:\n","            print(f\"No buildings detected in {os.path.basename(image_path)}.\")\n","\n","            if visualize:\n","                plt.figure(figsize=(10, 10))\n","                plt.imshow(original_image)\n","                plt.title(f\"No buildings detected in {os.path.basename(image_path)}\")\n","                plt.axis('off')\n","                plt.show()\n","\n","        return correct_predictions, total_predictions, per_building_results\n","    except Exception as e:\n","        print(f\"Failed to process {os.path.basename(image_path)}: {e}\")\n","        return 0, 0, []\n"],"metadata":{"id":"mP6v_AOdHTGu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 7: Main Processing Function"],"metadata":{"id":"m1I_HM7eIP3G"}},{"cell_type":"code","source":["# Main function to process all images in the class folders\n","def process_images_in_folders(data_folder, model, device, classification_model, class_labels, visualize=False):\n","    total_correct = 0\n","    total_predictions = 0\n","\n","    # Initialize per-class accuracy counts\n","    correct_predictions_per_class = {class_name: 0 for class_name in class_labels}\n","    total_predictions_per_class = {class_name: 0 for class_name in class_labels}\n","\n","    # Lists to collect actual and predicted labels for confusion matrix\n","    y_true = []\n","    y_pred = []\n","\n","    # Get list of class folders\n","    class_folders = [os.path.join(data_folder, d) for d in os.listdir(data_folder)\n","                     if os.path.isdir(os.path.join(data_folder, d))]\n","\n","    # Collect all image paths and their actual classes\n","    image_paths = []\n","    for class_folder in class_folders:\n","        class_name = os.path.basename(class_folder)\n","        images_in_class = [os.path.join(class_folder, f) for f in os.listdir(class_folder)\n","                           if f.lower().endswith(('.tif', '.jpg', '.png', '.jpeg'))]\n","        for img_path in images_in_class:\n","            image_paths.append((img_path, class_name))\n","\n","    # Shuffle image paths\n","    random.shuffle(image_paths)\n","\n","    # Process images sequentially\n","    for image_path, actual_class in tqdm(image_paths):\n","        try:\n","            correct, total, per_building_results = process_single_image(\n","                image_path, actual_class, model, device, classification_model, class_labels, visualize=True)\n","            total_correct += correct\n","            total_predictions += total\n","\n","            # Update per-class accuracy counts and collect labels\n","            for result in per_building_results:\n","                actual = result['actual_class']\n","                predicted = result['predicted_class']\n","                correct_predictions_per_class[actual] += int(result['correct'])\n","                total_predictions_per_class[actual] += 1\n","\n","                # Collect labels for confusion matrix\n","                y_true.append(actual)\n","                y_pred.append(predicted)\n","        except Exception as e:\n","            print(f\"Failed to process {image_path}: {e}\")\n","\n","    # Calculate overall accuracy\n","    if total_predictions > 0:\n","        accuracy = (total_correct / total_predictions) * 100\n","    else:\n","        accuracy = 0.0\n","\n","    print(f\"\\nTotal correct predictions: {total_correct}\")\n","    print(f\"Total predictions: {total_predictions}\")\n","    print(f\"Overall Accuracy: {accuracy:.2f}%\")\n","\n","    # Calculate and print per-class accuracy\n","    print(\"\\nAccuracy per class:\")\n","    for class_name in class_labels:\n","        correct = correct_predictions_per_class[class_name]\n","        total = total_predictions_per_class[class_name]\n","        if total > 0:\n","            class_accuracy = (correct / total) * 100\n","            print(f\"{class_name}: {class_accuracy:.2f}% ({correct}/{total})\")\n","        else:\n","            print(f\"{class_name}: No predictions.\")\n","\n","    # Generate confusion matrix and classification report\n","    if y_true and y_pred:\n","        # Generate confusion matrix\n","        cm = confusion_matrix(y_true, y_pred, labels=class_labels)\n","        plt.figure(figsize=(10, 7))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=class_labels, yticklabels=class_labels)\n","        plt.xlabel('Predicted')\n","        plt.ylabel('Actual')\n","        plt.title('Confusion Matrix')\n","        plt.show()\n","\n","        # Print classification report\n","        print(\"\\nClassification Report:\")\n","        print(classification_report(y_true, y_pred, labels=class_labels))\n","\n","        # Analyze misclassifications\n","        print(\"\\nMisclassified Samples:\")\n","        misclassified = [(true, pred) for true, pred in zip(y_true, y_pred) if true != pred]\n","        for actual, predicted in misclassified:\n","            print(f'Actual: {actual}, Predicted: {predicted}')\n","    else:\n","        print(\"No predictions to generate confusion matrix and classification report.\")"],"metadata":{"id":"3DionEPzHlSE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 8: Final function"],"metadata":{"id":"kGOlQDlBJgyz"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Data directory containing class folders\n","    data_folder = r'/content/drive/MyDrive/Madhu RA/val'  # Update the path to your data folder\n","\n","    # Define class labels (ensure these are in the correct order corresponding to your model's output)\n","    class_labels = ['Commercial', 'High', 'Hospital', 'Industrial', 'Multi', 'Schools', 'Single']  # Replace with your actual class names\n","\n","    # Load building detection model and device\n","    model, device = get_trained_model()\n","\n","    # Load the pre-trained classification model\n","    classification_model_path = r\"/content/drive/MyDrive/Madhu RA/Densenet201_best.h5\"  # Update the path to your model\n","\n","    # Load the classification model\n","    try:\n","        classification_model = load_model(classification_model_path)\n","        print(\"Classification model loaded successfully.\")\n","    except Exception as e:\n","        print(f\"Error loading classification model: {e}\")\n","        exit(1)\n","\n","    # Set to True to visualize all images\n","    visualize = True  # Visualization is enabled to inspect building detections\n","\n","    # Process all images in the data folder\n","    process_images_in_folders(data_folder, model, device, classification_model, class_labels, visualize)"],"metadata":{"id":"YO4wjdTxHTJe","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19HqEE5FiLxQS2IBK6Dx9HRh7oRk9odEZ"},"outputId":"8c6e2861-1fe7-44ef-9e3b-587e2b4a5371","executionInfo":{"status":"ok","timestamp":1729043244180,"user_tz":300,"elapsed":462334,"user":{"displayName":"Madhu Goutham Reddy Ambati","userId":"13555911222953113464"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}